{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXmCHcwKs6rd"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TE4fNAPWquom"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# Create a transform and normalise data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                              ])\n",
    "\n",
    "# Download FMNIST training dataset and load training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download FMNIST test dataset and load test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqMqFbIVrbFH"
   },
   "outputs": [],
   "source": [
    "class FMNIST(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(784, 128)\n",
    "    self.fc2 = nn.Linear(128,64)\n",
    "    self.fc3 = nn.Linear(64,10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    \n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "model = FMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNNyI5YRZ7H1"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        cum_loss += loss.item()\n",
    "     \n",
    "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWYw7ZOzsS8U"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "test_image_id = 0 \n",
    "img = images[test_image_id].view(1, 784) \n",
    "\n",
    "with torch.no_grad():\n",
    "    logps = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tRjoEDSqY8X"
   },
   "outputs": [],
   "source": [
    "ps = torch.exp(logps)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpP_RLV-qkc6"
   },
   "outputs": [],
   "source": [
    "nps = ps.numpy()[0]\n",
    "nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBf23XrtqrB6"
   },
   "outputs": [],
   "source": [
    "FMNIST_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sport Shoes','Bag','Ankle Boots']\n",
    "plt.xticks(np.arange(10),labels=FMNIST_labels,rotation='vertical')\n",
    "plt.bar(np.arange(10), nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "We2i1-GOqtC6"
   },
   "outputs": [],
   "source": [
    "img.size()\n",
    "img.squeeze().view(28,-1).size()\n",
    "plt.imshow(img.squeeze().view(28,-1),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxTiil7cXOAz"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    cnt = 0\n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        print(output)\n",
    "        cnt+=1\n",
    "        \n",
    "        if cnt > 0:\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ij_wa7paveM"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #set_trace()\n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        \n",
    "        pred = torch.argmax(output, 1)\n",
    "        total += labels.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyxadgAyiRqg"
   },
   "outputs": [],
   "source": [
    "pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojLPwZLdi3OX"
   },
   "outputs": [],
   "source": [
    "pred == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6V-3r9n-iCMb"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    #set_trace()\n",
    "    for images, labels in testloader:\n",
    "        \n",
    "        logps = model(images)\n",
    "        output = torch.exp(logps)\n",
    "        \n",
    "        pred = torch.argmax(output, 1)\n",
    "        total += labels.size(0)\n",
    "        num_correct += (pred == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the 10000 test images: {num_correct * 100 / total}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VNQH0g6F8xH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "04_03 validation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
